---
title: "Homework 3"
author: "Kelvin Delali Tamakloe"
date: 10/20/2021
output: github_document
---
```{r setup}
library(tidyverse)
library(dplyr)
library(p8105.datasets)
library(janitor)
library(readr)
```

# Question 1

## Instacart Dataset Exploration

Below, we will explore the instacart dataset

```{r}
data("instacart")
```

Brief Description:

Instacart is an American grocery delivery and pick up service company. 

The `instacart` dataset has data from the year 2017. There are `r nrow(instacart)` observations and `r ncol(instacart)` variables. 

In this dataset, the the total number of data points is `r nrow(instacart)*ncol(instacart)`. There are some key variables in this dataset including `r colnames(instacart)`.

## Total number of aisles and aisles from which the most items are ordered

The code below will tell us how many aisles there are, and from which aisles the most items are ordered.

```{r, message = FALSE, warning = FALSE}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))
```
There are a total 134 `aisles`. The aisles from which the most items are ordered are `fresh vegetables`, `fresh fruits`, and `packaged vegetables fruits` in that order.

## Plot of number of items ordered per aisle (> 10000 items ordered)

The code below generates a plot of the number of items ordered in each aisle but limited to aisles with more than 10000 orders.

```{r aisles_plot}
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  ggplot(aes(forcats::fct_reorder(aisle, (n)), n)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Number of items ordered per aisle",
    x = "Aisle name",
    y = "Number of items ordered",
    caption = "Data from instacart limited to aisles with more than 10,000 items ordered"
  )
```

## Table showing three most popular items in selected aisles 
The code below  produces a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”,with information on the number of items ordered.

```{r aisles_table}
instacart %>%
  filter(aisle == "baking ingredients" | 
           aisle == "dog food care" | 
           aisle == "packaged vegetables fruits") %>%
 count(aisle, product_name) %>%
  arrange(desc(n)) %>%
  group_by(aisle) %>%
  slice(1:3) %>%
  arrange(desc(n)) %>%
  group_by(aisle) %>%
  knitr::kable(caption = "Three Most Ordered Items Per Aisle")
```

From the table, `organic baby spinach`, `organic raspberries`, and `organic blueberries` 
are the three most ordered items from the `packaged vegetables fruits` aisle. 

Also, `light brown sugar`, `pure baking soda`, and `cane sugar` are the three most ordered items from the `baking ingredients` aisle. 

The three most ordered items from the `dog food care` aisle are `snack sticks chicken & rice recipe dog treats`, `organix chicken & brown rice recipe`, and `small dog biscuits`.


## Table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

```{r apples_ice_cream_table}
 instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
  ) %>%
  rename( "Sunday" = "0","Monday" = "1", "Tuesday" = "2", "Wednesday" = "3", "Thursday" = "4", "Friday" = "5", "Saturday" = "6") %>% 
  knitr::kable(caption = "Mean Hour of Day Ordered")
```
Generally, `Pink Lady Apples` are ordered earlier in the day than `Coffee Ice Cream`.

# Question 2

The code below will clean the `brfss_smart2010` data: formatting it to use appropriate variable names, 
focusing on the `Overall Health` topic, and only including factored responses ordered from`Poor` to `Excellent`.

```{r clean_brfss}
data("brfss_smart2010")
brfss_cleaned_version = brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(topic %in% c("Overall Health")) %>%
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>%
  arrange(response) %>%
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>%
  separate(locationdesc, into = c('state', 'location'), sep = ' - ')
```

## 2002: States observed at 7 or more locations

The code below will provide information on which states were observed at 7 or more locations in 2002.

```{r states2002}
states_2002 = brfss_cleaned_version %>% 
  filter(year == "2002") %>% 
  group_by(state) %>% 
  distinct(location) %>% 
  count(state) %>% 
  filter(n >= 7) %>% 
  select(state)
```

## 2010: States observed at 7 or more locations

The code below will provide information on which states were observed at 7 or more locations in 2002.

```{r states2010}
states_2010 = brfss_cleaned_version %>% 
  filter(year == "2010") %>% 
  group_by(state) %>% 
  distinct(location) %>% 
  count(state) %>% 
  filter(n >= 7) %>% 
  select(state)
```

In 2002, the states that were observed at 7 or more locations were `r states_2002$state`. 
In 2010, the states that were observed at 7 or more locations were `r states_2010$state`.

## Plot of Excellent responses

The code below will construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Furthermore, the code will make a “spaghetti” plot of this average value over time within a state 

```{r brfss_excellent}
Excellent_df = brfss_cleaned_version %>%
  filter(response %in% "Excellent") %>%
  select(year, locationabbr, data_value) %>%
  unique() %>%
  na.omit() %>%
  group_by(locationabbr, year) %>%
  mutate(
    avg_data_value = mean(data_value)) %>%
  select(year, locationabbr, avg_data_value) %>%
  distinct()
Excellent_df %>%
  ggplot(aes(x = year, y = avg_data_value)) +
  geom_line(aes(group = locationabbr, color = locationabbr)) +
  labs(
    title = "Average data value over time for states",
    x = "Year",
    y = "Average Data Value") +
  guides(col = guide_legend("State")) +
  theme(legend.position = "right")
```

## 2006/2010 Two-panel Plot of data_value distribution for Poor to Excellent responses in NY State location

The code below will make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

```{r panels}
brfss_panels = brfss_cleaned_version %>% 
  filter(year %in% c(2006,2010),
  state == "NY") 
ggplot(brfss_panels, aes(x = response, y = data_value, fill = response)) + 
  geom_boxplot() + 
  facet_grid(. ~ year) +
  labs(
    title = "Distribution of data_value for responses in NY",
    x = "Response",
    y = "data_value",
    caption = "Data from the brfss dataset"
  )
```

# Question 3 

```{r}
old_accel_data = read_csv("./accel_data.csv")
```

The code below will load, tidy, and otherwise wrangle the data. The final dataset produced will include all originally observed variables and values; have useful variable names; include a weekday vs weekend variable; and encode data with reasonable variable classes. 

```{r}
tidy_accel_df = old_accel_data %>% 
  pivot_longer(
    cols = activity.1:activity.1440,
    names_to = "activity_number",
    values_to = "activity_counts",
    names_prefix = "activity.",
  ) %>% 
  mutate(
    is_weekend = (day == "Saturday" | day == "Sunday")
    )
```

The tidied dataset `tidy_accel_df` contains `r nrow(tidy_accel_df)` rows (or observations) and `r ncol(tidy_accel_df)` variables. The dataset has variables which include: `r colnames(tidy_accel_df)`

##  Table of daily total activity 

The code below will aggregate across minutes to create a total activity variable for each day, and create a table showing these totals.

```{r}
total_activity = 
  tidy_accel_df %>% 
  group_by(day_id) %>% 
  summarize(total_activity_counts = sum(activity_counts))
knitr::kable(total_activity)
```

There are no obviously discernible trends in the patterns of daily activity. The daily activity counts appear to vary day-to-day in no set order.

## Single-panel plot of daily 24-hour activity time courses

The code below will generate a single-panel plot that shows the 24-hour activity time courses for each day with days of the week indicated by color.

```{r fig.width = 8, fig.height = 4}
tidy_accel_df %>% 
  mutate(activity_number = as.numeric(activity_number)) %>% 
  group_by(day, activity_number) %>% 
  summarize(avg_value = mean(activity_counts)) %>% 
  ggplot(aes(x = activity_number, y = avg_value, color = day)) +
  geom_smooth(se = FALSE) +
  scale_x_discrete(limit = c(360,720,1080,1440), 
                   labels = c( "6", "12", "18", "24")) +
  labs(
    title = "Daily 24-hour activity time courses",
    x = "Activity Number (hrs)",
    y = "Average Activity Counts",
    color = "Day"
  )
```

Generally, for all days in a week, activity counts trend downwards after 21:00 and remain low from that point till about 06:00. This may be due to sleep, as these periods of low activity would be expected to coincide with ones sleeping hours. There are peaks of average activity counts between 10:00 and 11:30 on Thursdays and around 21:00 on Fridays. The peaks coincide with ones waking hours and may be explained by physical activity as one goes about their daily tasks.